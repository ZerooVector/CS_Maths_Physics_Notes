#StochasticProcess 

现在我们开始讨论条件期望。令 $X,Y$ 是两个离散型随机变量，记 $p (i, j) = \mathbb{P}(X = i,Y = j)$，那么条件概率显然是：
$$
p(i|j) = \dfrac{p(i,j)}{\sum_{i}p(i,j)} = \dfrac{p(i,j)}{\mathbb{P}(Y = j)}
$$
可以定义条件期望：
$$
\mathbb{E}(f(X)|Y = j) = \sum_{i}f(i) p(i|j)
$$
但是这难以泛化到连续随机变量上：对于连续随机变量，$P(Y = j)$ 几乎等于零。设 $\mathcal{G}$ 是 $\mathcal{F}$ 的子 $\sigma$ 代数，$X$ 是期望有限的连续随机变量。给定 $\mathcal{G}$，$X$ 的条件期望 $Z = \mathbb{E}(X|G)$ 被定义为：$Z$ 在 $\mathcal{G}$ 上可测，并且对于任意 $A \in \mathcal{G}$，有：
$$
\int_{A}Z(\omega) \mathbb{P}(d  \omega) = \int_{A} X(\omega) \mathbb{P}(d \omega)
$$

>[!note] 条件期望的性质
>条件期望有如下性质：
>- $\mathbb{E}(aX+bY|\mathcal{G}) = a \mathbb{E}(X|\mathcal{G}) + b \mathbb{E}(Y|\mathcal{G})$
>- $\mathbb{E}(\mathbb{E}(X|\mathcal{G})) = \mathbb{E}(X)$
>- $\mathbb{E}(X|\mathcal{G}) = X$，如果 $X$ 是 $\mathcal{G}$ 可测的
>- $\mathbb{E}(X|\mathcal{G}) = \mathbb{E}X$，如果 $X$ 是独立于 $\mathcal{G}$ 的
>- $\mathbb{E}(XY| \mathcal{G}) = Y \mathbb{E}(X|\mathcal{G})$，如果 $Y$ 是 $\mathcal{G}$ 可测的
>- 如果 $\mathcal{H}$ 是 $\mathcal{G}$ 的子 $\sigma$ 代数，那么 $\mathbb{E}(X | \mathcal{H}) = \mathbb{E}(\mathbb{E}(X |\mathcal{H})|\mathcal{G})$

>[!note] 条件期望的琴生不等式
>设 $X$ 是期望有限的随机变量，$\phi$ 是凸函数，$\mathbb{E}|\phi (X)|< \infty$，那么：
> $\mathbb{E}(\phi (X)|\mathcal{G}) \ge \phi(\mathbb{E}(X|\mathcal{G}))$

给出两个随机变量 $X,Y$，$X$ 对 $Y$ 的条件期望是由 $\mathcal{G} = \sigma(Y)$ 确定：
$$
\mathcal{G} = \sigma(Y) = \{Y^{-1}(B),B \in \mathcal{R}\}
$$
为了加深理解，我们可以看看这个概念是如何被简化到离散随机变量的情况上，设 $\Omega_{j} = \{\omega: Y(\omega) = j\}$，此时 $\mathcal{G}$ 是 $\Omega_{j}$ 的所有可能的并集。根据前面的定义：
$$
\int_{\Omega_{j}}\mathbb{E}(X|Y) \mathbb{P}( d \omega) = \int_{\Omega_{j}} X(\omega) \mathbb{P}(d \omega)
$$
这意味着：
$$
\mathbb{E}(X|Y) = \dfrac{1}{\mathbb{P}(\Omega_{j})} \int_{\Omega_{j}}  X(\omega) \mathbb{P}(d \omega)
$$
这与上面的定义符合。

条件期望的性质可以帮助我们证明一些不等式：

>[!note] 关于条件期望的一个不等式
> $\mathbb{E}(X - \mathbb{E}(X|Y))^{2} \le \mathbb{E}(X - g(Y))^{2}$

证明是依赖于直接的计算
$$
\mathbb{E}(X - g(Y))^{2} = \mathbb{E}(X - \mathbb{E}(X|Y))^{2} + \mathbb{E}(\mathbb{E}(X|Y) - g(Y))^{2} + 2 \mathbb{E}[(X - \mathbb{E}(X|Y))(\mathbb{E}(X|Y - g(Y)))]
$$
使用一步条件期望的性质：
$$
\begin{align*}
\mathbb{E}((X - \mathbb{E}(X|Y))(\mathbb{E}(X|Y) - g(Y)))\\
&= \mathbb{E}[\mathbb{E}[(X - \mathbb{E}(X|Y))(\mathbb{E}(X|Y) - g(Y))|Y]]\\
&= \mathbb{E}[(\mathbb{E}(X|Y) - \mathbb{E}(X|Y))(\mathbb{E}(X|Y) - g(Y))]\\
&= 0\\
\end{align*}
$$
从而得证。


接下来我们给出收敛的定义：设 $\{X_{n}\}$ 是一列定义在概率空间 $(\Omega, \mathcal{F}, \mathbb{P})$ 上的随机变量，$X_{n}$ 的分布是 $\mu_{n}$，设 $X$ 是具有分布 $\mu$ 的随机变量。我们接下来引入四种收敛：
- 几乎处处收敛：$\mathbb{P}(\omega: X_{n}(\omega ) \rightarrow X (\omega)) = 1$
- 依概率收敛：对于任意 $\epsilon > 0$，$P (\omega:|X_{n}(\omega) - X (\omega)| > \epsilon) \rightarrow 0$
- 依分布收敛：对于任意 $f(x)$，都有 $\mathbb{E}f (X_{n}) \rightarrow \mathbb{E} f(X)$
- $L_{p}$ 收敛：$\mathbb{E}|X_{n}-X|^{p}\rightarrow 0$，特殊地，对于 $p=1$ 称为均值收敛；对于 $p=2$ 称为均方收敛

现在我们需要给出各种收敛之间的关系：
>[!note] 各种收敛之间的关系
>- 几乎处处收敛意味着依概率收敛
>- 依概率收敛意味着我们可以选出一个几乎处处收敛的子列
>- 如果 $p<q$，那么 $L^{q}$ 收敛意味着 $L^{p}$ 收敛
>- $L^{p}$ 收敛意味着依概率收敛
>- 依概率收敛意味着依分布收敛

第二条我们暂时不给出证明。其余的证明如下：
对于 a)，根据定义：
$$
\mathbb{P}(|X_{n}(\omega) - X(\omega)| > \epsilon) = \int_{|X_{n} - X| > \epsilon}(\omega) \mathbb{P}(d \omega) \rightarrow  0
$$
对于 c)，使用 Holder 不等式：
$$
\mathbb{E}|X_{n} -X|^{p} \le (\mathbb{E}(|X_{n} - X|^{p})^{\frac{q}{p}})^{\frac{p}{q}}= (\mathbb{E}|X_{n}-X|^{q}  )^\frac{p}{q}
$$
对于 d)，这是切比雪夫不等式的结果：
$$
\mathbb{P}(\omega:|X_{n}(\omega) - X(\omega)| > \epsilon) \le  \dfrac{1}{\epsilon^{p}}\mathbb{E}|X_{n}-X|^{p}
$$
对于 e)，使用反证法证明。若存在一个连续有界函数 $f(x)$ 和一个子序列 $X_{n_{k}}$，使得 $\mathbb{E} f (X_{n_{k}}) \not \rightarrow \mathbb{E} f(X)$，那么我们可以从 $X_{n_{k}}$ 中选出一个进一步的子序列（仍记为 $X_{n_{k}}$），使得它几乎处处收敛到 $X$，从而根据支配收敛定理，我们可以导出矛盾。

现在我们研究特征函数：随机变量 $X$ 的特征函数为：
$$
f(\xi ) = \mathbb{E}exp(i \xi X) = \int \exp(i \xi X) \mu(dx)
$$
>[!note] 特征函数的性质
>- $\forall \xi \in \mathbb{R}$，$|f (\xi) | \le 1$，$f (\xi) = \overline{f(- \xi)}$，$f(0)=1$
>- $f$ 一致连续。

现在对第二条给出证明：
$$
|f(\xi _{1}) - f(\xi _{2})| = |\mathbb{E}(\exp(i \xi _{1}X) - \exp(i \xi_{2}X ))| \le \mathbb{E} |1 - \exp(i (\xi _{2} - \xi _{1})X)|
$$
我们可以给出一些分布的特征函数：
![[Pasted image 20240802184217.png]]

下面这个关于特征函数的定理可以帮助我们更简单地证明中心极限定理：
>[!note] Levy 的连续性定理
>设 $\{\mu_{n}\}$ 是一列概率测度，而 $\{f_{n}\}$ 是对应的特征函数，假设：
>- $f_{n}$ 在 $\mathbb{R}$ 上逐点收敛到 $f$
>- $f$ 在 $\xi = 0$ 处是连续的
>那么 $\mu_{n}$ 依分布收敛到 $\mu$，并且 $f$ 是 $\mu$ 的特征函数。反过来，假如 $\mu_{n}$ 依分布收敛到 $\mu$，那么 $f_{n}$ 在任意有限区间上一致收敛到 $f$，且 $f$ 是 $\mu$ 的特征函数。

显然，密度函数和特征函数之间其实是傅里叶变换对的关系，因此：
$$
\rho(x) = \dfrac{1}{2\pi} \int \exp( - i \xi x) f(\xi )d \xi  
$$
我们说一个特征函数 $f$ 是半正定的，如果它对于任意一组 $\{\xi_{1} , \cdots ,\xi_{n}\}$，矩阵 $[f(\xi _{i} - \xi_{j})]$ 是半正定的。

>[!note] 特征函数的半正定性质
>函数 $f$ 是某种概率测度的特征函数，当且仅当它是半正定的且在 0 处连续。

这里我们只证明一半（另一半比较难）：
$$
\sum_{i,j} f(\xi_{i} - \xi_{j}) v_{i} \bar v_{j} = \int_{\mathbb{R}} \left|\sum_{i} v_{i}\exp(i \xi _{i}x)\right| dx \ge  0
$$

对于离散型随机变量，我们可以类似地引入生成函数：
$$
G(x) = \sum_{k=0}^{\infty} P(X = x_{k})x^{k}
$$
那么显然可以看到：
$$
P(X = x_{k}) = \dfrac{1}{k!} G^{(k)} (x)|_{x = 0}
$$
我们将两个序列的卷积定义为：$c_{k}= \sum_{j=0}^{k}a_{j} b_{k-j}$。容易发现：如果三个生成函数定义为：$A (x) = \sum_{k} a_{k}x^{k}, B (x) = \sum_{k} b_{k} x^{k}, C (x) = \sum_{k} c_{k}x^{k}$，并且满足 $c_{k} = a_{k}* b_{k}$，那么 $C (x) = A(x)B(x)$。因此显然的一点是：设 $X,Y$ 是两个独立的随机变量：$P (X=j) = a_{j} , P (Y = k) = b_{k}$，则 $X+Y$ 的生成函数恰好是 $C (x) = A(x)B(x)$。我们可以给出常用分布到生成函数如下：
![[Pasted image 20240802210502.png]]

此外，对于连续型、离散型随机变量，我们还可以统一地定义矩母函数：
$$
M(t) = \mathbb{E} \exp(tX) 
$$
显然可以注意到它的一些性质：
$$
M^{(n)} (t) = \mathbb{E}(X^{n} \exp(tX)) \ \Rightarrow\ \mathbb{E}X^{n} = M^{(n)}(0)
$$
那么我们可以将 $M(t)$ 写成级数的形式：
$$
M(t) = \sum_{i=0}^{\infty} \mathbb{E}X^{n} \dfrac{t^{n}}{n!}
$$
另外，如果 $X,Y$ 是独立的，那么显然有 $M_{X+Y}(t)  = M_{X}(t) + M_{Y}(t)$。下面给出一些常见分布的矩母函数：
![[Pasted image 20240802211244.png]]

累计生成函数 $K(t)$ 由下式定义：
$$
K(t) = \log M(t) = \log \mathbb{E}(\exp(tX)) = \sum_{n=0}^{\infty} \kappa_{n} \dfrac{t^{n}}{n!}
$$
从而我们有 $\kappa_{0} = 0$，以及：
$$
\kappa_{n} = \dfrac{\mathrm{d}^{n}}{\mathrm{d}t^{n}} K(0)
$$
