 #StochasticProcess 

**本小节的主要内容是：概率的公理化定义、条件概率、**

我们定义：样本空间 $\Omega$ 是随机试验中可能出现的所有结果的集合，其中的元素 $\omega \in \Omega$ 被称为样本点。一个 $\sigma$ 代数 $\mathcal{F}$ 是 $\Omega$ 的子集的集合，且满足下列条件：
- $\omega \in \mathcal{F}$
- 如果 $\mathcal{A} \in  \mathcal{F}$，那么 $\mathcal{A}^{c} \in \mathcal{F}$
- 如果 $A_{1}, A_{2} ,\cdots  \in \mathcal{F}$，那么 $\cup_{n=1}^{\infty} A_{n} \in \mathcal{F}$
$\mathcal{F}$ 中的每一个集合 $A$ 称为一个事件。设 $\mathcal{B}$ 是一个 $\Omega$ 子集的集合，那么我们将最小的包含 $\mathcal{B}$ 的 $\sigma$ 代数称为由 $\mathcal{B}$ 生成的 $\sigma$ 代数。我们将 $(\Omega ,\mathcal{F})$ 称为一个可测空间。

概率测度 $\mathbb{P} : \mathcal{F} \rightarrow [0,1]$ 被是定义在 $\mathcal{F}$ 上的几何函数，它满足：
- $\mathbb{P}(\emptyset) = 0 , \mathbb{P}(\Omega) = 1$、
- 若 $A_{1}, A_{2} ,\cdots$ 两两不交，那么：
$$
\mathbb{P}\left(\bigcup_{i=1}^{\infty} A_{i}\right)  = \sum_{i} \mathbb{P}(A_{i})
$$
这被称为 $\sigma$ 可加性。在这个情况下，集合论的知识可以被用于回答概率论的问题。例如，$A = A \cup (B  \cap A^{c})$，那么 $\mathbb{P}(A \cup B) = \mathbb{P}(A) + \mathbb{P}(B  \cup A^{c}) \le \mathbb{P}(A) + \mathbb{P}(B)$。

给定 $A, B \in  \mathcal{F}$，且假设 $\mathbb{R}(B) \not = 0$，在给定 $B$ 的条件下，$A$ 发生的条件概率定义为：
$$
\mathbb{P}(A|B) = \dfrac{ \mathbb{P}(A \cap B)}{\mathbb{P}(B)}
$$
此外，由于 $\mathbb{P}(AB) = \mathbb{P}(A|B) \mathbb{P}(B)$，我们自然也可以推广，例如：
$$
\mathbb{P}(ABC) = \mathbb{P}(A|BC) \mathbb{P}(B|C) \mathbb{P}
(C)$$
此外，我们自然可以得到贝叶斯公式：设 $A_{1}, A_{2},\cdots$ 是彼此不交的事件，并且 $\cup_{i=1}^{\infty} A_{i} = \Omega$，那么我们有：
$$
\mathbb{P}(A_{i}|B) = \dfrac{\mathbb{P}(A_{i}) \mathbb{P}(B|A_{i})}{\sum_{i} \mathbb{P}(A_{i}) \mathbb{P}(B|A_{i})}
$$
我们称 $\mathbb{P}(A_{i})$ 是事件 $A_{i}$ 发生的先验概率，而 $P(A_{i}|B)$ 则称为后验概率。

接下来我们考虑一些离散分布。设此时样本空间中的元素是有限的或是可数的，也就是 $\Omega  = \{\omega_{1},\omega_{2},\cdots \}$，现在定义随机变量 $X$ ，将 $\omega_{i}$ 映射到 $x_{i}$，定义 $p_{i} = \mathbb{P}(X = x_{i})$，给定 $X$ 的一个函数 $f$，其期望定义为：
$$
\mathbb{E}f(X) = \sum_{i}f(x_{i})p_{i}
$$
或者更一般地，我们定会一分布的 $p$ 阶矩被定义为：
$$
m_{p} = \sum_{i} x_{i}^{p} p_{i}
$$
除了一阶矩（期望）之外，另一个重要的量是方差：
$$
\mathrm{Var}(X) = m_{2} - m_{1}^{2} = \sum_{i}(x_{i} - m_{1})^{2}p_{i}
$$

接下来我们再看一些连续的分布。定义 $\mathcal{R}$ 是 $\mathbb{R}$ 上的 Borel $\sigma$ 代数，也就是包含了所有开集的最小 $\sigma$ 代数。我们称一个随机变量 $X$ 是 $\mathcal{F}$ 可测的实值函数 $X : \omega \rightarrow \mathbb{R}$。也就是说，我们在 $\mathbb{R}$ 上定义了 $\sigma$ 代数 $\mathcal{R}$，$\mathcal{R}$ 中的每一个元素 $B \in  \mathcal{R}$ 都与事件集合 $\mathcal{F}$ 中的一个元素对应：$X^{-1}(B) \in \mathcal{F}$。随机变量 $X$ 的分布是一个定义在 $\mathbb{R}$ 上的概率测度：
$$
\mu(B) = \mathbb{P}(X \in B) = \mathbb{P} \circ  X^{-1}(B)
$$
特别地，对于 $B_{0} = (- \infty , x]$，我们定义了分布函数 $f (x) = \mu (B_{0})$。
如果对于任意 $B \in \mathcal{R}$，都可以找到一个可积的函数，使得：
$$
\mu(B)=  \int_{B} \rho(x) dx
$$
我们就称 $\rho(x)$ 是 $X$ 的概率密度函数。我们可以将 $\rho(x)$ 写成 $\rho (x) = \dfrac{\mathrm{d}\mu}{\mathrm{d}m}|_{x}$，这是概率测度 $\mu(dx)$ 相对于勒贝格测度 $dm(x)$ 的导数。
我们将连续分布的期望定义为：
$$
\mathbb{E}X = \int_{\Omega} X(\omega ) \mathbb{P}(d \omega) = \int_{\mathbb{R}} x \mu(dx)
$$
方差定义为：
$$
\mathrm{Var}(X)  = \mathbb{E}(X - \mathbb{E}X)^{2}
$$
随机变量 $X,Y$ 的协方差定义为：
$$
\mathrm{Cov} (X,Y )  =  \mathbb{E}(X- \mathbb{E}X) (Y  - \mathbb{E} Y)
$$
如果 $\mathrm{Cov}(X, Y) = 0$，那么我们称 $X,Y$ 不相关。
对于任意的 $p \ge 1$，我们将 $L^{p}(\Omega)$ 定义为 $p$ 阶矩有限的随机变量的集合：
$$
L^{p}(\Omega) = \{X(\omega) : \mathbb{E}|X|^{p}  < \infty \}
$$
对于其中的 $X$，我们将其 $p$ 范数定义为：
$$
||X||_{p} = (\mathbb{E}|X|^{p})^\frac{1}{p}
$$

>[!note] 关于随机变量的一些不等式（此处不给出证明）
>Minkowski 不等式：$||X+Y||_{p} \le ||X||_{p} + ||Y||_{p}, p>1$
>Holder 不等式：$\mathbb{E}|(X, Y)| \le ||X||_{p}||Y||_{q} , p > 1, \dfrac{1}{p} + \dfrac{1}{q} =1$。
>Schwartz 不等式：$\mathbb{E}|(X, Y)| \le ||X||_{2}||Y||_{2}$ （是 Holder 不等式的特殊情况）

>[!note] 切比雪夫不等式
> 对于随机变量 $X$，设对于某个 $p > 0$， $\mathbb{E}|X|^{p} <  \infty$，那么 $\mathbb{P}\{|X| \ge  \lambda\} \le  \dfrac{1}{\lambda^{p}}\mathbb{E}|X|^{p}$

证明很简单：
$$
\mathbb{E}|X|^{p}= \int |x|^{p} \mu(dx)  \ge \int_{|x| \ge  \lambda} |x|^{p} \mu(dx) \ge \lambda^{p}\int_{|x| \ge  \lambda} \mu(dx) = \lambda^{p}\mathbb{P}(|X| \ge  \lambda)
$$
这个不等式可以被推广到如下形式：对于非负单增的函数 $f (x)$：
$$
\mathbb{P}(|X| \ge \lambda) \le  \dfrac{ \mathbb{E} f(|X|) }{f(\lambda)}
$$

>[!note] 琴生不等式
>设 $X$ 是期望有限的随机变量，$\phi : \mathbb{R} \rightarrow \mathbb{R}$ 是凸函数，$\mathbb{E}|\phi(X)|$ 有限，那么 $\mathbb{E}\phi (X) \ge \phi(\mathbb{E}X)$。

现在给出一些连续分布的典型例子：均匀分布、指数分布、正态分布：
$$
\rho(x) = \dfrac{1}{(2\pi)^{\frac{n}{2}}(\det \Sigma)^{\frac{1}{2}}}\exp\left(- \dfrac{1}{2}(x- \mu)^{T} \Sigma^{-1}(x- \mu) \right)
$$
此时 $\mathbb{E}(X) =\mu,\mathrm{Cov}(X) = \Sigma$。对于 $\Sigma$ 不可逆的情况，这意味着一些分量可以被其他分量线性表出，这个时候需要使用特征函数定义高斯分布。
对于一个 $6n$ 维的随机向量：$x = (x_{1},x_{2},\cdots ,p_{1},p_{2},\cdots)$，分布：
$$
\pi(x) = \dfrac{1}{Z} \exp(- \beta H(x))
$$
称为玻尔兹曼分布，其中：
$$
Z = \int_{\mathbb{R}^{6n}} \exp(- \beta H(x)) dx
$$
称为配分函数。


我们现在研究独立的概念。我们称事件 $A, B \in \mathcal{F}$ 称为是独立的，如果：
$$
\mathbb{P}(A \cap B) = \mathbb{P}(A) \mathbb{P}(B)
$$
我们称随机变量 $X,Y$ 是独立的，如果对于 $\mathcal{R}$ 中的任意两个集合 $A,B$，$X^{-1}(A),Y^{-1}(B)$ 是独立的。我们将两个随机变量的联合分布定义为 $(X,Y)$ 的分布，设 $X,Y$ 的分布为 $\mu_{1},\mu_{2}$，而联合分布为 $\mu$，对于 $A, B \in \mathcal{R}$，我们有：
$$
\mu(A \times B) = \mu_{1}(A ) \mu_{2}(B)
$$
如果 $\mu_{1},\mu_{2}$ 的 PDF 由 $p_{1},p_{2}$ 给出，那么 $\mu$ 的 PDF 由 $p (x, y) = p_{1}(x)p_{2}(y)$ 给出。显然我们有：$\mathbb{E}f_{1}(X) f_{2}(Y) = \mathbb{E}f_{1}(x) \mathbb{E}f_{2}(Y)$，实际上这个也可以作为独立的定义。以上讨论可以被拓展到多个事件 $\{A_{k} \}$：
$$
\mathbb{P}\left(\bigcap_{j} A_{i_{j}}\right) = \prod_{i} \mathbb{P}(A_{ij})
$$
 注意：$\{A_{k}\}$ 中的事件两两独立，不意味着上式成立！多个随机变量的独立定义类似。

 
