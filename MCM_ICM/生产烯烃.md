#MCM  
![[Pasted image 20230429193121.png]]

## 获奖队伍 #1 
### 第一问：研究温度的影响
首先，该队伍不是将所有实验放在一起研究的，而是先将所有实验分为四类。
![[Pasted image 20230429195430.png|400]]
分类的依据如下（具有相同特性的被分到一组）：
- 在第一组中，装料的比率相同
- 在第二组中，Co 负载量、装料比率都相同
- 在第三组中，只有催化剂质量比变化
- 在第四组中，A 13, A 14 和 A 7, A 8 分别构成对照试验

计算温度与乙醇转化率、C 4 烯烃选择性的 Pearson 相关系数
![[Pasted image 20230429201535.png|400]]

之后，我们可以进行线性或者非线性的拟合
![[Pasted image 20230429201812.png|600]]

本文得到的结论是，二次曲线相关性最强，因此使用二次曲线拟合。但是，实际上，乙醇转化率和选择性都不可能无限上升。因此使用 Logistic 是更好的做法。
之后，为了分析一次特定的实验过程中的情况，作者先对所有副产物进行了系统聚类，从而实现降维（主要附加产物、次要附加产物）。此后，对各个产物比率随着时间的变化进行拟合，分析结论即可。
![[Pasted image 20230429202538.png|600]]

### 问题 2：研究不同的催化剂组合和温度对产物的影响
在这一部分中，作者建立了两种模型
#### 模型一：使用 ANOVA 选择重要变量，再进行最小二乘回归
首先，将催化剂拆开，分别将催化剂中的每一个成分作为自变量
![[Pasted image 20230429203322.png|400]]
检验**方差齐次**之后（这里有问题），进行 ANOVA，发现所有自变量全都显著，自变量和温度的交互项也全都显著。
==CHATGPT== 
在进行方差分析（ANOVA）时，检验方差齐次性（homogeneity of variance）是一个关键的前提假设。这是因为 ANOVA 的原理是基于不同组之间的方差比较，以确定这些组的均值是否存在显著差异。方差齐次性假设指的是各组内的方差相等，即各组数据的波动程度相同。

检验方差齐次性的原因有以下几点：
1. 结果的准确性：如果方差齐次性假设不成立，ANOVA 的结果可能不准确。在方差不齐的情况下，F 检验统计量可能会高估或低估实际效应，从而导致错误地拒绝或接受原假设。
2. 统计功效：当方差齐次性假设不满足时，ANOVA 的统计功效（即检测到实际效应的概率）可能会降低，增加第二类错误的风险（即未能拒绝错误的原假设）。
3. 违反假设的后果：当方差齐次性假设严重受到侵犯时，ANOVA 的结果可能不可靠。在这种情况下，研究者可能需要使用针对方差不齐数据的替代统计方法，如 Welch's ANOVA 或 Brown-Forsythe 等。
为了验证方差齐次性假设，可以使用 Levene 检验、Bartlett 检验等统计方法。如果检验结果表明方差齐次性假设不成立，研究者可以采用更稳健的方法来处理这个问题，例如使用前述的 Welch's ANOVA 或 Brown-Forsythe 等替代方法。

那么将所有自变量丢入线性回归式
![[Pasted image 20230429204028.png|600]]

**做完最小二乘回归之后觉得自己的模型没有说服力怎么办？可以进行残差的正态性检验。每次回归之后建议都做一次**

#### 模型二：Partial LS
==ChatGPT==  
偏最小二乘回归（Partial Least Squares Regression，简称 PLS 回归）是一种统计学方法，用于建立多元线性回归模型。PLS 回归主要用于处理具有多重共线性（即自变量之间高度相关）的数据集。在这种情况下，传统的多元线性回归方法可能会遇到问题，例如模型的稳定性较差，预测准确性降低等。而 PLS 回归通过将自变量进行降维来解决这个问题，提高模型的稳定性和预测能力。
PLS 回归的主要步骤如下：
1. 数据标准化：为消除数据量纲的影响，通常需要对自变量（X）和因变量（Y）进行标准化处理，使其均值为 0，标准差为 1。
2. 提取主成分：PLS 回归通过提取自变量（X）和因变量（Y）的主成分（又称潜变量）来降低数据维度。这些主成分是原始变量的线性组合，能最大化 X 与 Y 之间的协方差。
3. 构建 PLS 回归模型：通过最小化预测误差平方和（或类似的准则），确定主成分的系数。这些系数用于构建 PLS 回归模型，将降维后的自变量与因变量联系起来。
4. 选择主成分个数：通过交叉验证等方法，确定合适数量的主成分以达到最佳的预测性能。
5. 预测和模型评估：使用构建好的 PLS 回归模型对新数据进行预测，并通过一些评估指标（如均方误差、R 方等）来衡量模型的预测准确性。
PLS 回归的优点包括：
- 可处理具有多重共线性的数据集，提高模型的稳定性。
- 通过降维可以降低模型复杂性，提高计算效率。
- 适用于自变量数量大于观测数量的情况。
然而，PLS 回归也有一定的局限性，例如解释性较差，因为主成分通常难以直接解释为实际问题中的变量。因此，在使用 PLS 回归时，需要权衡其优缺点，结合具体问题来选择合适的方法。

##### Example ： 一个来自 ChatGPT 的 PLS 的例子
假设我们想要通过两个自变量 X 1 和 X 2（例如房屋的面积和卧室数量）来预测房价（Y）。我们有一个包含 100 个观测值的数据集。但这两个自变量之间存在较强的相关性，也就是具有多重共线性。在这种情况下，我们可以使用 PLS 回归来处理这个问题。
1. 数据标准化：首先，我们需要对 X 1、X 2 和 Y 进行标准化处理，使它们的均值为 0，标准差为1。
2. 提取主成分：在这个例子中，我们尝试提取一个主成分。PLS 回归会找到一个新的潜变量（Z），它是 X 1 和 X 2 的线性组合（Z = a * X 1 + b * X 2），同时最大化了 Z 与 Y 之间的协方差。
3. 构建 PLS 回归模型：我们可以找到一个系数 c，使得 Y 与 Z 之间的预测误差平方和最小。因此，PLS 回归模型可以表示为：Y = c * Z。
4. 选择主成分个数：在这个简单的例子中，我们只使用一个主成分。在实际应用中，如果有更多的自变量，我们需要通过交叉验证等方法来确定合适的主成分数量。
5. 预测和模型评估：使用构建好的 PLS 回归模型，我们可以对新数据进行预测。同时，通过计算均方误差、R 方等指标，评估模型的预测准确性。
在这个简单的例子中，PLS 回归通过将多重共线性的自变量降维为一个潜变量，从而使得预测模型更稳定，提高预测能力。

**总结一下：实际上，PLS 是尝试对多个自变量和多个因变量分别提取主成分，再对主成分进行 OLS**
之后，这一组将每个 $y$ 回归到所有主成分上，再将主成分还原。之后就得到了回归方程。
![[Pasted image 20230429210308.png|500]]

最后，作者对比了两个子模型的结果，并认为它们效果差不多。并对结果进行了分析。

### 问题三：C 4 烯烃收率最大化模型
优化目标：C 4 烯烃收率=乙醇转化率 xC 4 烯烃选择性，因此
$$
\rho = y_{1}\times y_{2}
$$
约束条件：
- 所有生成物的选择性之和=100（）
- 所有催化剂的成分都有取值范围
此外，在拟合烯烃收率的过程中，还增加了几个交互项

### 问题四：新的实验设计
使用均匀设计的方法设计五组实验，最后一组舍弃，换上问题三中求出的最大值的情况。









