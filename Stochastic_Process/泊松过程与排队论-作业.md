#StochasticProcess  

## 2-6 冗余系统的可靠性
==首先给出一个暴力，但并不能做出最终答案的方法==
由题意得，$X_{i}$ 服从参数为 $\lambda_{i}$ 的指数分布。因此，$\sum_{i=1}^{n} X_{i}$ 应当服从 Gamma 分布。记 $X = \sum_{i=1}^{n}X_{i}$：
$$
F_{X}(t) = 1-\sum_{i=0}^{n-1}\frac{(\mu_{1} t)^{i}e^{-\mu_{1}t}}{i!}
$$
$$
F_{Y}(t) = 1- \sum_{i=0}^{m-1} \frac{(\mu_{2} t)^{i}e^{-\mu_{2} t }}{i!}
$$
那么
$$
P(\min(X,Y)<t) = 1-P(X>t)P(Y>t) = 1- \sum_{i=0}^{n-1}\frac{(\mu_{1} t)^{i}e^{-\mu_{1}t}}{i!}\sum_{j=0}^{m-1} \frac{(\mu_{2} t)^{j}e^{-\mu_{2} t }}{j!}
$$
为了方便叙述，记 $Z = \min(X,Y)$，那么显然有：
$$
f_{Z}(t) = \frac{\mathrm{d}P(\min(X,Y)<t)}{\mathrm{d}t} = \frac{\mu_{1}\exp(\mu_{1}t)(\mu_{1}t)^{n-1}}{(n-1)!}\sum_{j=0}^{m-1}\frac{(\mu_{2}t)^{j} \exp(-\mu_{2}t )}{j!} + \frac{\mu_{2}\exp(\mu_{2}t)(\mu_{2}t)^{m-1}}{(m-1)!}\sum_{i=0}^{n-1}\frac{(\mu_{1}t)^{j} \exp(-\mu_{1}t )}{i!} 
$$
积分求解期望即可：
$$
\mathrm{E}[Z] = \int_{0}^{\infty} tf_{Z}(t) dt
$$

==再给出答案上的思路==
将 I 型零件和 II 型零件失效的过程建模成两类泊松过程。那么 I 类过程的强度为 $\mu_{1}$，II 类过程的强度为 $\mu_{2}$，两类过程的强度之和就是 $\mu_{1}+\mu_{2}$，取定条件：在第 $N$ 次到达时机器损坏，那么这次损坏的时间期望为：
$$
\mathrm{E}(t|n=N) = \frac{N}{\mu_{1}+\mu_{2}}
$$
对 $N$ 取期望，我们就知道了：
$$
\mathrm{E}[N] = \frac{\mathrm{E}[N]}{\mu_{1}+\mu_{2}}
$$
那么我们只需求出 $\mathrm{E}[N]$。注意到 $N$ 只能取在 $[\min(m,n),m+n-1]$ 之间（对于左端点，这个机器的运气太差，以至于坏掉的都是 I 类型或者 II 类型的零件，结果一种零件完全没消耗，而另一种耗光了；对于右端点，这个机器的运气太好，以至于一种零件耗光了，另一种恰好剩下一个）。
那么，我们计算第 $k$ 次到达时机器损坏的概率：这有两种可能：第一种，在前 $k-1$ 次到达中，$n$ 个 I 类型零件已经坏了 $n-1$ 个，这次损坏的恰好又是 I 类型的零件；第二种，在前 $k-1$ 次到达中，$m$ 个 II 类型零件已经坏了 $m-1$ 个，这次坏的恰好又是 II 类型。考虑到对于任意的一次到达，损坏的零件为 I 型的概率是 $\mu_{1}/(\mu_{1}+\mu_{2})$，损坏的为 II 型的概率是 $\mu_{2}/(\mu_{1}+\mu_{2})$，根据上面的语言叙述， $\mathrm{E} [N]$ 可以用如下的方程表达：
$$
\mathrm{E}[N]  = \sum_{k = \min(m,n)}^{m+n-1} k\left[ C_{k-1}^{n-1} \left(\frac{\mu_{1}}{\mu_{1}+\mu_{2}}\right)^{n}  \left(\frac{\mu_{2}}{\mu_{1}+\mu_{2}}\right)^{k-n} +C_{k-1}^{m-1} \left(\frac{\mu_{1}}{\mu_{1}+\mu_{2}}\right)^{k-m}  \left(\frac{\mu_{2}}{\mu_{1}+\mu_{2}}\right)^{m} \right]
$$
这样我们就得到了答案的结果。

## 2-8 生成 Poisson 随机变量
注意到：
$$
P(X_{i}<t) = P\left(-\frac{\ln U_{i}}{\lambda}<t\right)= P(U_{i}> \exp (-\lambda t)) = 1- \exp(-\lambda t)
$$
那么
$$
f_{X}(t) = \lambda \exp (-\lambda t)
$$
命题得证。
由于指数分布和泊松分布之间的联系，我们考虑一个强度为 $\lambda$ 的 Poisson 过程在 $[0,1]$ 这段时间上的到达数量，并用 $X_{i}$ 代表第 $i-1$ 个到达和第 $i$  个到达之间的等待时间。那么，到达的次数 $n$ 应当满足：
$$
\sum_{i=1}^{n} X_{i} \le 1 \le \sum_{i=1}^{n+1} X_{i}
$$
将题目中 $X_i$ 的定义代入并化简即可得到：
$$
\prod_{i=1}^{n} U_{i} \ge  e^{-\lambda} \ge \prod_{j=1}^{n+1} U_{i}
$$
命题得证。

## 2-9 不均匀硬币
要想以 $N_i$ 次掷硬币丢出 $n_{i}$ 次第 $i$ 个面，那么我们就需要在前 $N_{i}-1$ 次掷硬币中丢出 $n_{i}-1$ 次，在第 $N_{i}$ 次恰好掷出第 $i$ 个面。那么，$N_{i}$ 的分布是负二项分布：
$$
P(N_{i} = k) = C_{k-1}^{n_{i}-1} p_{i}^{n_{i}}(1-p_{i})^{k-n_{i}}
$$
这些 $N_{i}$ 显然不是互相独立的。假设你掷出硬币的第 1 面的次数很多，那么 $N_{1}$ 就很小，相应地，$N_{i}(i \not = 1)$ 就要增大。因此 $N_{i}$ 不独立，且两两之间有负的协方差。
我们将掷出第 $i$ 面的概率记为 $p_{i}$，将掷出第 $i$ 面的事件称为第 $i$ 类事件。那么，第 $i$ 类事件的到达过程就是在从一个强度为 1 的泊松过程上以 $p_{i}$ 的概率采样，那么采样得到的就是强度为 $p_{i}$ 的泊松过程。$T_{i}$ 可以看作是第 $i$ 类事件到达 $n_{i}$ 次所需的时间总和。那么它显然服从参数为 $n_{i}$ 和 $p_{i}$ 的 Gamma 分布：
$$
f_{T_{i}}(t) = \frac{\lambda\exp(-p_{i}t)(p_{i} t)^{n_{i}-1}}{(n_{i}-1)!}
$$
根据本书中的命题 2.3.2，在这种情况下，掷出次数的随机变量是独立的 Poisson 变量，因此这些 $T_i$ 也应当是独立的。
==Gamma 分布的期望是已知的，这里问的应该是 $\mathrm{E}[T]$ 的表达式==
$$
\begin{align*}
\mathrm{E}[T] &= \int_{0}^{\infty} P(T_{i}>t)dt \\
&= \int_{0}^{\infty} (\prod_{i=1}^{r} \int_{t}^{\infty} \frac{\lambda\exp(-p_{i}t)(p_{i} t)^{n_{i}-1}}{(n_{i}-1)!} )
\end{align*}
$$
由于 $\mathrm{E}[T] = \mathrm{E}[N \mathrm{E} [X]] = \mathrm{E} [N]$，因此：
$$
\mathrm{E} [N] = \mathrm{E} [T]
$$

## 2-17 次序统计量
按照题目 (a)中的叙述，$i-1$ 个变量小于 $x$ 的概率为 $(F(x))^{i-1}$，$n-i$ 个变量大于 $x$ 的概率为 $(\bar F(x))^{n-i}$ ，那么我们可以证得 $X_{(i)}$ 的密度函数为：
$$
f_{X_{(i)}} = \frac{n!}{(i-1)!(n-1)!} (F(x))^{i-1} (\bar F(x))^{n-i} f(x)
$$
在 $X_{(i)}<x$ 时，说明第 $i$ 个最小者已经小于 $x$，那么可以有 $i$ 个，$i+1$ 个，$i+2$ 个，......，$n$ 个小于 $x$ 。那么：
$$
P(X_{(i)}<x) = \sum_{k=i}^{n} C_{k}^{n} (F(x))^{k}(1-F(x))^{n-k}
$$
我们将 $X_{i}$ 的分布取为 $[0,1]$ 上的均匀分布，那么利用 (a)和 (b)中的结果，得到：
$$
\int_{0}^{y} \frac{n!}{(i-1)!(n-1)!} x^{i-1} (1-x)^{n-i} dx = \sum_{k=i}^{n} C_{k}^{n} y^{k} (1-y)^{n-k}
$$
如果 $S_{i}<N(t)$，也就是说，第 $i$ 个事件是在 $t$ 时刻前发生的。那么，$S_{1}, S_{2}\cdots ,S_{n}$ 与 $[0,t]$ 上均匀分布的 $n$ 个随机变量的 $n$ 个次序统计统计量有相同的分布。那么到达时间的分布：
$$
f_{S_{i}} (x) = \frac{n!}{(i-1)!(n-i)!}(\frac{x}{t})^{i-1}(\frac{1-x}{t})^{n-i}  \frac{1}{t} dx
$$
到达时间的期望为
$$
\mathrm{E}(S_{i}) = \int_{0}^{t}  x f_{S_{i}}(x)
$$
==实际上可以不需要真的计算这个积分，我们可以直观地求解== 在长度为 $t$ 的时间区间内随机放入 $n$ 个事件，这些事件将区间均匀分成了 $n+1$ 段，那么其中第 $i$ 个事件发生的时间的期望应该是：
$$
\mathrm{E}[S_{i} | N(t) = n] = \frac{t}{n+1} i \quad (i \le n)
$$
由于 Poisson 过程是有无记忆性的，那么在 $t$ 之后，两个事件到来的时间间隔期望也是 $t/(n+1)$ ，因此
$$
\mathrm{E}[S_{i}|N(t) = n] = t + \frac{i-n}{n+1}t
$$
==这一问不确定做的对不对，因为按理说 (e)应该可以用上 (d)的结论，但是我没有用上==
==这似乎说明带有 $t$ 的更新区间比其他的区间更长，可能与课本 72 页的定理不谋而合？==

## 2-24 追逐
==这题是直接看的答案==
由于车辆进入公路是一个 Poisson 过程，我们从这个 Poisson 过程上采样：考虑一个以速度 $v$ 在时刻 $t$ 进入公路的车辆 $A$，如果一辆在时刻 $s$ 以速度 $X$ 进入的车辆 $B$ 与 $A$ 相遇，那么“$B$ 进入公路”这一事件就被计数一次；如果 $B$ 与 $A$ 没有相遇，那么“$B$ 进入公路”这一事件就不被计数。也就是说，以 $G$ 记旅行时间的分布，那么一个发生在时刻 $s$ 的事件被计数的概率为：
$$
p(s) = 
\begin{cases}
\bar G (t+t_{v}-s) \quad  s<t \\
G(t+t_{v}-s) \quad  t<s<t+t_{v}  \\
0 \quad others
\end{cases}
$$
因此，总共的计数次数的期望为：
$$
\lambda \int_{0}^{t}\bar G(t+t_{v}-s)ds +\lambda\int_{t} ^{t+v} G(t+t_{v}-s)ds = \lambda \int_{0}^{t_{v}} G(y)dy +\lambda \int_{t_{v}}^{t+t_{v}} \bar G(y) dy
$$
对上式求导，并且考虑到在 $t \rightarrow \infty$ 时，$\bar G (t+t_{v}) \rightarrow 0$ ，得到：
$$
G(t_{v})  -0 + \bar G(t+t_{v}) - \bar G(t_{v}) = 0 \Rightarrow G(t_{v}) = \bar G(t_{v}) \Rightarrow G(t_{v}) = \frac{1}{2}
$$
从而证得了原命题。本题非常巧妙，重点还是利用“相遇”这一事件平稳增量、独立增量的特性，将其建模为 Poisson 过程。


---
## 2-32 非时齐 Poisson 过程
==没做完，不会==
我们直接证明一个加强的结论：到达时间的有序集合 $S_{1}, S_{2},\cdots ,S_{n}$ 与 $n$ 个具有 $F(x)$ 分布的变量的次序统计量有相同的分布。仿照定理 2.3.1 的证明过程，我们找到 $0<t_{1}<t_{2}<\cdots <t_{n+1} = t$，并且找到足够小的 $h_{i}$，使得 $t_{i}+h_{i}<t_{i+1}$，那么：
$$
\begin{align*}
P(t_{i}&\le S_{i}\le t_{i}+h_{i},i=1,2,\cdots,n|N(t) = n)\\
&= \frac{\prod_{i}\lambda(t_{i})h_{i}\exp(-\lambda(t_{i})h_{i})\cdot \exp(-(m(t)-\sum_{i}\lambda(t_{i})h_{i}))}{\exp(-m(t))(m(t))^{n}/n!}\\
&= \frac{n! \prod_{i}\lambda(t_{i})}{(m(t))^{n}} \prod_{i}h_{i}
\end{align*}
$$
那么，到达时间的联合分布为：
$$
f(t_{1},t_{2},\cdots ,t_{n}) = n! \frac{ \prod_{i}\lambda(t_{i})}{(m(t))^{n}}
$$
而次序统计量的联合密度为：
$$
f(x_{1},x_{2},\cdots ,x_{n}) = n! \prod_{i}f(x_{i}) = n!\frac{\prod_{i}\lambda(x_{i})}{(m(t))^{n}}
$$
那么，到达时间的联合概率密度和具有 $F(x)$ 分布的次序统计量的联合概率密度相同。
==由于这里不确定它说的“在分布 $F$ 的时间内无法工作”到底是不是指上一问中的分布 $F$，为了避免混淆，我们将工人无法工作的时间的分布先记为 $G$。== 对于一名在 $S_{i}$ 时刻受伤的工人来说，在 $t$ 时刻仍然受伤的概率为 $1-G(t-S_{i})$。取条件于在 $[0,t]$ 中工人受伤的人数 $N$，那么：
$$
\mathrm{E}[X(t) |N=n] = \mathrm{E}\left[\sum_{i=1}^{n} 1-G(t-S_{i})\right] = n - n \mathrm{E}[G(t-S_{i})]
$$
再对 $N$ 取期望：
- 但是这个 $E[G(t-S_{i})]$ 消不去啊，尽管我们在 (a)问中已经知道了 $S_i$ 的分布
---

## 2-41 条件 Possion 过程
没有独立增量的原因是，根据本书 2.6 节的介绍，我们只要知道一段时间内发生的事件数目，我们就可以推断出 $\Lambda$ 的分布，从而 $\Lambda$ 的分布又可以影响其他时间段上发生的事件数目。因此，两个时间段上发生的事件数目是不是互相独立的。因此，Poisson 分布没有独立增量。在给定的条件 $N (t) = n, S_{i} = s_{i}$ 时：
$$
P(\Lambda = \lambda|N(t) =n,S_{i}=s_{i}) = \frac{P(\Lambda = \lambda,N(t) = n,S_{i}=s_{i})}{P(N(t)=n,S_{i}=s_{i})} 
$$
其中：
$$
P(\Lambda = \lambda,N(t) = n,S_{i}=s_{i}) = \frac{\exp(-\lambda t)(\lambda t)^{n}}{n!} \frac{n!}{t^{n}} dG(\lambda)
$$
$$
P(N(t) = n,S_{i}=s_{i}) = \int_{0}^{\infty} \frac{\exp(-\lambda t)(\lambda t)^{n}}{n!} \frac{n!}{t^{n}} dG(\lambda)
$$
那么：
$$
P(\Lambda = \lambda|N(t) =n,S_{i}=s_{i}) = \frac{\exp(-\lambda t)(\lambda t)^{n}dG(\lambda)}{\int_{0}^{\infty}\exp(-\lambda t)(\lambda t)^{n}dG(\lambda)}
$$
因此，$\Lambda$ 的条件分布只与 $n$ 有关。我们也就说它只通过 $N(t) = n$ 依赖于历史。
在 $N (t) =n$ 的条件下，下一次到达间隔的概率密度为：
$$
f(S_{n+1}-S_{n}=t_{0}|N(t) = n) = \frac{\int_{0}^{\infty}\lambda \exp(-\lambda t_{0} ) (\lambda t)^{n}\exp(-\lambda t)dG(\lambda)}{\int_{0}^{\infty}(\lambda t)^{n}\exp(-\lambda t)dG(\lambda)}dt_{0}
$$
$$
P(N(h) \ge 1) = 1-P(N(h) = 0) = 1- \int_{0}^{\infty} \exp(-\lambda h )dG(\lambda)
$$
因此，设这里的积分和极限符号可以交换：
$$
\lim_{h \rightarrow 0} \frac{P(N(h) \ge 1)}{h} = \lim_{h \rightarrow0}\frac{1- \int_{0}^{\infty} \exp(-\lambda h )dG(\lambda)}{h} = \lim_{h \rightarrow0} \frac{\int_{0}^{\infty} 1-\exp(-\lambda h)dG(\lambda)}{h} = \int_{0}^{\infty} \lambda dG(\lambda)
$$

它们是同分布的。但是由 (a)中论述可知，它们不是独立的。
