#KD  #Research 

这部分内容来源于文章*KNOWLEDGE DISTILLATION FOR FEDERATED LEARNING: APRACTICAL GUIDE*

这篇文章是一篇综述文章，主要讲了两件事：（1）由于传统的加权平均策略依赖于每个本地模型是同质化的，而且有诸多缺点（需要交互的信息太多，仍然可能导致泄密风险，等等）所以要使用 KD 来在本地模型是不同的情况下实现 FL（2）由于本地数据都不一致，因此直接使用加权平均策略可能导致模型表现下降，因此，FL 算法需要使用 KD 来减轻数据异质性的影响。


