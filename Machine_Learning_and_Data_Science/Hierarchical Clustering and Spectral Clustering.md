#MLorDS 

这一部分中，我们给出除了 k-Means 聚类以外的其他几种聚类方法

## 层次聚类
这是所有聚类算法中最为简单的一种方法！我们先来介绍背景知识：如何度量两个数据簇之间的距离？
- 最近点距离：遍历两个簇中的每一对数据，找到最近值
- 最远点距离：两簇内数据的最远间隔
- 均值点距离：**考察两个簇质心的距离**
- 平均距离：**遍历两个簇之间的每一个点，计算所有距离的平均值**
- Ward's 距离：
![[Pasted image 20230314094525.png]]
我们不看第二行的式子，而是看第一行的式子。它可以被写成下面的形式：
![[Pasted image 20230314094642.png]]

也就是说，Ward 距离衡量了**如果将两个类别合并起来，离差平方和相对于合并前的变化是多少**，这也就是合并两个类别的代价。这一代价越大，说明两个类别之间的距离也越远。

层次聚类的算法非常简单：***每次只选择当前局面上，距离最近的两个点（或者两个簇，或者一个簇和一个点）进行合并*** ，直到所有数据被聚合在一起。
例如，下图中的一步聚类，我们将 "d","g"两个点聚为一类，"b","e"两个点聚为一类。
![[Pasted image 20230314095126.png]]


## 谱聚类
谱聚类也是一种**图论算法** 
首先，谱聚类计算样本点**两两之间的距离**，这个距离可以用很多种方式描述，例如使用欧氏距离。那么，我们可以得到距离成对矩阵 $D$ ：
![[Pasted image 20230314095343.png|300]]

之后，因为我们要将数据分为两类，因此，我们希望衡量一下数据间的相似性。我们使用 Gauss 核函数将距离转换为相似度：
$$
\mathrm{sim}(i,j)=  \exp(- \frac{||x^{(i)}-x^{(j)}||^{2}}{\sigma^{2}})
$$
之后，可以得到相似度矩阵
![[Pasted image 20230314095732.png|300]]

利用相似度矩阵，我们可以建图，并且通过某些切割方式，切断图上的某些边，从而起到将数据划分为几类的效果。切割方式可以是最小割，也可以是别的什么东西。
![[Pasted image 20230314100016.png|300]]

但是，谱聚类算法不直接在图上进行操作，而是通过对图的邻接矩阵进行降维，得到 Laplace 矩阵，再对 Laplace 矩阵进行特征值分解的方式来找到“切割”原图的方法。
==以下内容原本需要十分严整的数学推导，但这里我们略去证明过程==

首先构造一张图的度矩阵 (Degree Matrix)，其对角线元素是相似度矩阵 $S$ 的对应列元素之和:
$$
G_{ij} =  \sum_{j=1}^{n}s_{ij} = \mathrm{diag }(\mathcal{1}^T S)
$$
然后你有三种方法从度矩阵得到 Laplace 矩阵：
![[Pasted image 20230314124151.png]]

把 Laplace 矩阵进行特征值分解，从前几个特征向量上可以看出划分数据的明显特征。
==根据书上的说法，这相当于将高维数据投影到一个低维空间，但是这个说法可能不合理== 
==这里留待研究，写得很不清楚==






