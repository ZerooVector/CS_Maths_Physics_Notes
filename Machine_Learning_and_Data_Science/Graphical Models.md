#MLorDS 
图模型主要用于将随机变量“解耦”，减轻它们之间的相互依赖，从而简化计算。这种模型主要包括：使用了变量之间的一些独立性的贝叶斯信念网络、假设了历史完全无效的马尔可夫链，等等。

## 贝叶斯信念网络
一句话介绍：
$$
P(x_{1},\cdots,x_{n}) = \prod_{i=1}^{n}P(x_{i}|\mathrm{parents}(x_{i}))
$$
一个贝叶斯网络描述为：$N = (G,\Theta)$，其中，$G = (V,E)$，而 $\Theta =[\theta_{1},\cdots ,\theta_{n}]$ 代表了一个节点 $i$ 在其父节点条件下的概率（一张条件概率表）

### 如何理解条件独立
如果在条件 $Z$ 下，有：
$$
P(X,Y|Z) = P(X|Z)P(Y|Z)
$$
但是
$$
P(X,Y) \not = P(X)P(Y)
$$
这是因为
$$
P(X,Y) = \sum_{Z}P(X,Y,Z) = \sum_{Z}P(X|Z)P(Y|Z)P(Z)
$$
因此，这样的性质称为条件独立


## HMM 

### Markov Chain
我们考虑变量 $X_{i}$ 只能在状态空间中取值，且
$$
P(x_{i}^{(t+1)}|\mathrm{History}) = P(x_{i}^{(t+1)}|x_{i}^{(t)})  
$$
隐马尔可夫过程包括一个观测变量序列 $o^{(t)}$ 和一个隐变量序列 $q^{(t)}$，其中隐变量可取的值为 $S_{1},\cdots S_{N}$，而观测变量可取的值为 $V_{1},\cdots ,V_{M}$。我们使用矩阵 $A$ 代表隐变量的状态转移，
