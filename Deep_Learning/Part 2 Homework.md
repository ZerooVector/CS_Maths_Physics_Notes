#DL 

## 问题 1 
搜索算法是在有限的消耗之内，找到问题的一个最优解或者可行解的方法。一般来说，一个搜索问题的状态空间使用 $(S,F,C,I,G)$ 五元组描述，其中 $S$ 是状态的集合，F 是状态转换函数，C 是代价函数，I 是初始状态，G 是目标状态。我们需要在状态空间中找到一条由初始状态到达目标状态的、代价最小的路径。

## 问题 2 
要使用 A-star 算法解决 TSP，搜索空间中的状态应该是从起始城市出发，历经 $n$ 个城市后到达第 $n+1$ 个城市这一过程（即每个状态保存一个长度为 $n+1$ 的数组，数组中的每个元素代表经过的一个城市），同时，每个状态还需要保存已经经过的路径长度。在评估每个状态时，使用的启发式函数可以是目前到达的城市到最近一个未访问城市的距离，这样就可以保证启发式函数小于真实的剩余距离，从而确保 A-star 算法可以找到最优解。因此，算法的伪代码如下：
- STEP 1：初始化，将状态{初始城市}放入 open 表
- STEP 2 ：在 open 表中选择估价函数最小的状态进行扩展，将该状态放入 close 表中，将其后继状态加入 open 表
- STEP 3：检查目前目标状态是否被放入 close 表中，如果没有，则反复执行 STEP 2，直到目标状态在 close 表中为止
- STEP 4：根据搜索得到的状态序列输出最优路径

## 问题 3
策略网络用于评估在棋盘上不同位置落子的优劣。具体来说，策略网络将输出一个概率值，概率值越大的位置可能对后续赢得游戏越有利。策略网络的作用是减少搜索空间。在围棋中，每一步都有数百甚至上千种可能的落子位置，这使得搜索所有可能性非常困难。策略网络可以帮助 AlphaGo 快速锁定一些最有希望的落子位置，从而降低后面使用蒙特卡洛搜索树时的搜索空间和计算复杂度。
价值网络用于评估当前棋局的优劣。给定一个棋局，价值网络预测当前玩家获胜的概率。在围棋游戏中，通常需要遍历多个步骤来评估一个落子位置的优劣。价值网络可以直接提供一个快速粗略的局面评估，从而减少许多不必要的搜索。这使得 AlphaGo 能够在有限时间内完成搜索和决策。

## 问题 4
例子：
![[Pasted image 20230613225015.png]]
解答：
![[2064b79e96014ba76a55c63519044d5.jpg]]


## 问题 5
探索是指在解空间中搜索新的、未知的解。进化算法通过变异和重组等操作来实现探索。其中，变异是一种随机操作，它对个体的某些基因进行随机改变。例如，在遗传算法中，变异可能是将某个基因位从0变为1，或从1变为0。这种操作有助于跳出局部最优解，从而发现新的潜在解；重组是在两个或多个个体间进行基因交换的过程。它将不同个体的特征组合在一起，生成新的个体。这种操作有助于在解空间中探索新的可能性。
利用是指在已知的优秀解附近搜索更好的解。进化算法通过选择操作来实现利用。选择操作根据个体的适应度（Fitness）对种群进行筛选。适应度较高的个体更有可能被选中并进入下一代。这样做可以保留优秀个体的基因，从而在已知的优秀解附近搜索更好的解。


## 问题 6
算法的基本步骤如下：
1. **编码**：将神经网络的权重和偏置表示为一个一维数组（基因型），这将成为我们优化算法的个体。
2. **初始化种群**：随机生成一组初始权重和偏置，创建一个包含 100 个个体的的种群。
3. **适应度函数**：将训练集上损失函数的负值作为适应度函数，用于评估解的质量。
4. **选择**：根据适应度函数，选择种群中表现较好的个体进入下一代。可以使用锦标赛选择、轮盘赌选择或其他选择策略。
5. **交叉（重组）**：通过交叉操作生成新个体。选择两个父代个体，将它们的权重和偏置进行交换以产生一个或两个新的子代。由于这里的权重和偏置都是实数，因此我们可以使用仿二进制交叉的方法
6. **变异**：对子代个体进行变异操作。以一定概率随机改变子代个体的权重和偏置，通常可以在权重和偏置上加一个正态分布的随机变量。
7. **终止条件**：设置终止条件，例如最大迭代次数、适应度阈值等。当满足终止条件时，算法停止，并返回当前最优个体。
8. **迭代过程**：重复进行选择、交叉、变异操作，直到满足终止条件。




