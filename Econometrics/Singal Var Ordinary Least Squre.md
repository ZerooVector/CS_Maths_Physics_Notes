---
banner: "![[banner12.png]]"
---

#Econometrics  #MCM
# 0 Introduction to Econometrics

一个“定义”：计量经济学是以经济理论为基础，以经济数据表现得事实为依据，运用数学和统计方法，通过建立数学模型来探究经济数量关系和规律的一门学科。

## 建立模型
通常来讲，一个经济模型中必须包括：经济变量、经济参数、随机误差项。**模型必须兼顾真实性和实用性**，过分复杂和过分简单的模型都不是好的模型！此外，方程中的变量必须具有可观测性，自行引入的变量越少越好！

## 估计参数 

## 模型的检验
**经济意义检验（检验你的结果是否符合经济意义，在数学建模里这一步相当重要）**，统计推断检验（检验结果是否只是一个统计推断的偶然结果）、计量经济学检验（是否符合计量经济方法的基本假定）、预测检验

解释变量、被解释变量

内生变量：模型求解的结果外生变量：模型以外的变量

截面数据、时间序列、面板数据

---

# 1 普通最小二乘法的推导、性质和应用

## 简介

如果我们希望研究大豆的产量与施肥的关系、旅游业的总收入与中国居民的收入水平的关系，那么我们需要将一个变量回归到另一个变量上，这就需要普通最小二乘法。

研究两个随机变量之间的相关关系，我们需要**总体线性相关系数**

$$\rho = \frac{Cov(X,Y)}{\sqrt{Var(X)Var(Y)}}$$

我们使用如下的方程描述两个变量的线性因果关系：

$$Y = \alpha x+ \beta +\epsilon$$


在需要的情况下，可以对变量进行合适的数学变换，从而将非线性的模型转换成线性的模型。该模型主要需要以下假设：
- 相关关系确实存在
- 误差项服从均值为 0 的正态分布
- 误差序列同方差（这也是正态分布的必然要求），即 $Var(\epsilon_i) = \sigma^2$
- 误差序列没有自相关性，即 $Cov(\epsilon_i,\epsilon_{i+1}) = 0$

这样的假设给了回归方程一个解释：

$$E(Y) = \alpha X+\beta$$

我们回归的这个 $Y$ 实际上是数据的中心（期望值），$X$ 每增长 $1$ 个单位，$Y$ 的期望（或者说，平均而言）就增长 $\alpha$ 个单位。

## 参数估计

- 最小二乘估计：使得残差平方和最小

$$\min \sum_i[Y_i-(a+bX_i)]^2$$

- 极大似然估计：使得似然函数极大化

$$\max \prod \exp(-\epsilon_i^2)$$

显然可以看出来两个估计方式是等价的

最小二乘估计的方程组是

$$\sum_i e_i = 0 \qquad \sum_i e_ix_i = 0$$

这两个方程也可以从矩估计的方式来理解，也就是

$$E(e_i) = 0 \qquad E(x_ie_i) = 0$$

（第二个式子里，$x_i$ 是常数，可以提出来）


## 最小二乘的性质：

- 线性性：估计量可以写作 $Y_i$ 的线性组合

$$a,b = \sum_i \lambda Y_i$$

在下面的讨论中，我们记

$$\omega_i = \frac{X_i-\bar X}{\sum_i (X_i-\bar X)^2}$$

它有一些显然的性质：

- $$\sum \omega_i = 0$$
- $$\sum \omega_i (X_i-\bar X) = 1$$
- $$\sum \omega_i^2 = \frac{1}{\sum_i (X_i-\bar X)^2}$$

利用上面的求和式，容易证明，最小二乘估计量有一些性质

- $a,b$ 的无偏性，即 $E(a) = \alpha\ , E(b) = \beta$
- 估计量的方差 $Var(b) = \sigma^2 \sum_i \omega^2  \qquad  Var(a) = \sigma^2(\frac{1}{n} +\frac{\bar X^2}{\sum(X_i - \bar X^2)})$
- 这两个估计量的方差会趋向于 0，这也就引出了最小二乘估计量的一致性，即 $\lim_{n\rightarrow \infty}P(|b-\beta|<u)  = 1$
- **高斯-马尔可夫定理**：在所有线性无偏估计量里面，最小二乘估计量已经是方差最小的估计量

## 单变量模型的评价

我们的模型希望最小化残差平方和，因此，残差平方和本身就是一个衡量拟合程度的指标。但是由于残差平方和与样本点的个数有关，因此我们不能直接使用。因此，通常我们有一个分解：

$$\sum_i (Y_i-\bar Y)^2 = \sum_i(\hat Y_i-\bar Y)^2+\sum_i e_i^2$$

也就是

$$SST = SSR+SSE$$

离差平方和相当于只用数据的平均值进行估计的结果，显然应当是最差的。那么，残差平方和 $SSE$ 占离差平方和 $SST$ 的比例就表现了回归模型的优劣，因此，我们定义：

$$R^2 = \frac{SSR}{SST}$$

称为**决定系数**，显然，更高的决定系数意味着更好的回归模型（注意，把决定系数和**样本相关系数**区分开来！）

## 对单变量模型中的参数进行假设检验

上面对于参数 $a,b$ 方差的估计量中含有 $\sigma$，我们需要线将 $\sigma$ 估计出来，我们不加证明地给出：

$$E(\sum_i e_i^2) = \sigma^2(n-2)$$

那么，$S^2$ 为 $\sigma^2$ 的无偏估计

$$S^2 = \frac{\sum e_i^2}{n-2}$$

那么我们可以得到

$$t_b = \frac{b-\beta}{\sqrt{S^2/\sum_i (X_i -  \bar X)^2}}$$

服从自由度为 $n-2$ 的 t 分布（分子上是正态分布，分母上因为 $\sum_i e_i^2$ 的存在，是卡方分布）

这个统计量可以用来做：
- 区间估计 
- 假设检验 
- 预测
	- 点预测：直接代入
    
    $$Y^\star = aX^\star+b$$
	- 区间预测：利用 $Y^\star/e^\star$


对于多变量的最小二乘，请参阅下一份笔记
[[Multi Vars OLS]]


