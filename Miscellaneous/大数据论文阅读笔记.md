
## VIDEO (LANGUAGE) MODELING: A BASELINE FOR GENERATIVE MODELS OF NATURAL VIDEOS
![[Pasted image 20240301190854.png]]
没有“生成”，依然是一个判别式模型。思路很简单：首先将图像分割成 8 $\times$ 8 的小块，由于这些小块太多，于是聚类到 10000 个中心上。将同一位置的小块以及其附近的 8 个块送入一个 RNN 网络，预测下一个时间步上这个位置是什么（10000 选 1）. 
这是一个强大的基线模型（在 2014 年），其中这种方法是从 NLP 中借鉴的，同时这里显然融合了 RNN 和 CNN。

## Unsupervised Learning of Video Representations using LSTMs
![[Pasted image 20240301191833.png]]
一个 LSTM 可以同时实现输入视频的重构和视频的生成。可以处理简单的人造视频了。这篇文章里面讨论了有条件生成和无条件生成的问题。该模型无法预测一些真实的视频。
![[Pasted image 20240301191937.png]]

## RECURRENT ENVIRONMENT SIMULATORS
![[Pasted image 20240301193234.png]]
视频生成模型最初的目的之一。这里在解码的时候加上了 $a_{t}$，那个时候这种模型是在强化学习中预测接下来一段时间的环境的。这也是为什么很早就有人吹嘘（？）这种模型是所谓“世界模型”。

## Attentive Semantic Video Generation using Captions
从无约束视频生成蜕变到有约束视频生成，允许用户输入一句话的 Caption。Caption 和视频都会通过 LSTM 进行编码，两者进行 Attention 计算之后获得隐状态，送入解码器进行解码。
![[Pasted image 20240301195416.png]]

## Stochastic Video Generation with a Learned Prior
仍然使用 LSTM 作为视频的编码器与解码器。与之前的工作不同的是：这篇论文认为之前的生成模型都是确定性的。因此，这篇文章同时学习一个先验分布，在生成视频的时候从这个先验分布中做个采样，和 Encoder 输出的东西一起送入 Decoder 中。
![[Pasted image 20240301205811.png]]

