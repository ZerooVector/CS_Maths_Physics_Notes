#OPTandOR 
在这一部分中，我们的问题通常是没有理论证明它可以找到全局最优解的。甚至，这些函数是不可微的，这使得我们无法利用梯度信息。因此，我们必须使用启发式算法来解决这些问题。

# Algo 1 : 局部搜索
局部搜索是指不断地对现有解做局部的改进。
![[Pasted image 20230323162615.png|400]]

## Hill-Climbing Algo
- 寻找当前解的邻域内有没有比当前解更高的解，如果有，跳到更高的解；如果没有，结束！
这样的算法可以求解很多问题，例如背包问题、选址问题等等。
![[Pasted image 20230323163628.png|400]]
这些问题有明显的目标函数。然而，登山搜索可以求解没有明显目标函数的问题。
E.g. $n$ 皇后问题
对于这种问题，你需要人为地定义目标函数：例如，我们定义皇后的冲突对数为要最小化的目标函数；对于邻域的定义，我们启发式地找到目前冲突数最多的皇后，并且将其可取的位置作为邻域解！
![[Pasted image 20230323164002.png|400]]

这种算法被称为“最小冲突启发式”算法
![[Pasted image 20230323164411.png|400]]

最小冲突问题的实例是基站分配问题。例如，一个区域不能被两个相同频段的基站覆盖，例如下面的不满足要求：
![[Pasted image 20230323164954.png|300]]


##### Example 旅行商问题
![[Pasted image 20230323165809.png|400]]

在旅行商问题中，登山搜索的速度很快，但是效果很差
![[Pasted image 20230323170300.png|400]]

旅行商问题中还有很多定义邻域的方式
![[Pasted image 20230323170430.png|300]]
![[Pasted image 20230323170439.png|300]]

## 改进的登山搜索
![[Pasted image 20230323171914.png|400]]

- 首选登山搜索：随机选择邻域解
![[Pasted image 20230323172144.png]]

- 随机登山搜索
![[Pasted image 20230323172209.png|400]]

跳到邻域解的概率是：
![[Pasted image 20230323172400.png|400]]
在有多个邻域解的时候，跳跃概率可以写成：
$$
P_{i}= \frac{e^{\frac{f_{i}}{T}}}{\sum_{j} e^{\frac{f_{j}}{T}}}
$$

- 侧向移动：允许跳跃到与原始点相等的邻域点
- 随机重启登山搜索（运行多次登山搜索）

## 类似于登山搜索的算法：局部束搜索
![[Pasted image 20230323173548.png]]

也就是说，局部搜索中，有 $k$ 个智能体同时爬山，但是它们的记忆是共享的：每一次爬山时，智能体将“传送”到整体搜索到的前 $k$ 个最优位置，而不是各自走到各自找到的最优位置

在机器翻译中，有时候会使用束搜索的思想

![[Pasted image 20230330152253.png|300]]
![[Pasted image 20230330152050.png|300]]







