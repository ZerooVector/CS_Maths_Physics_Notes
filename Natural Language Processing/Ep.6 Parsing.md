#NLP 

词汇的共现规律可能是由于其他原因导致的！我们如何对这种原因（结构）显式地建模？现在，我们要求模型进行更加复杂的推断。

对于一个句子，我们有两种建模方法：
- 短语结构句法分析：使用上下文无关文法来建模。这使得我们可以使用树形结构建模一个句子。直观上，这种分析在分析短语的结构（句子->短语->词）
- 依存结构句法分析：通过分析词与词之间的关系来分析句法。
![[Pasted image 20231102133445.png|400]]

## 短语结构句法分析
如果使用规则句法分析的方法，我们可能无法找到唯一的句法树。所以，我们实际有规则方法、概率方法、神经网络方法三种基本的实现方式。

### 规则方法：CYK 策略
对于 Top-Down 的方法，很简单，只要依次应用规则，匹配不到就回溯。直到句法树完全扩展, 且覆盖了句子中所有的字符。对于 Bottom-Up 和 Left-Corner 的方法也是类似的。
下面，我们说明 CYK 策略。我们举个例子来说。假定有六个规则：
![[Pasted image 20231102135649.png|400]]

下一步：
![[Pasted image 20231102135837.png|400]]

最后，我们可以得到：
![[Pasted image 20231102140402.png|400]]

时间复杂度 $O(n^{3}|R|)$ ：三个自由度： $i,j$，以及在哪个位置断开判断前后合并。其中 $n$ 是词的数目，$|R|$ 是规则数目
这个算法不能消除歧义，一定概率合并出多个 S（多个句法树）

### PCFG 方法
加概率的方式：
![[Pasted image 20231102141814.png|400]]

条件独立性假设：
![[Pasted image 20231102142921.png|400]]

推断最优句法树的动态规划方法：
![[Pasted image 20231102144613.png|400]]

### 神经网络的方法
![[Pasted image 20231102145250.png|400]]



## 依存句法分析





### 神经网络方法
![[Pasted image 20231109133738.png|400]]
![[Pasted image 20231109133824.png|400]]
这里面，我们希望预测 $v_{h},v_{m}$ 的特性，我们可以取出词特征、段特征、距离特征。
或者来判断动作：
![[Pasted image 20231109133936.png|400]]

使用 NN 计算树的打分：
![[Pasted image 20231109134108.png|400]]

StackLSTM：
![[Pasted image 20231109134254.png|400]]

#### 现代句法分析
- 固定为语言学句法结构——相当于使用了外部知识
- 自行发现适合任务的树结构
- 结构信息隐含在表示中


目标 1：
![[Pasted image 20231109134822.png|400]]
使用 GCN，使得模型可以建模图结构。


目标 2：
目标是用句法结构进行句子表示学习；每一步规约没有指导，只有一个最终的目标——通常会用下游任务来指导
![[Pasted image 20231109135333.png|400]]

目标 3：
复杂的神经模型 (如 Transformer)可以学到句法和语义信息 
预训练的词嵌入包含丰富的句法和语义信息
![[Pasted image 20231109140437.png|400]]


->去掉连接词的显式篇章关系分析数据为什么不能增强隐式篇章关系分析的效果？

