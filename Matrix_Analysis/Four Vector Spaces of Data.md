#MA 

## 数据矩阵中蕴含的四个线性（向量）空间
- 由 $X$ 的列向量张成的空间叫做列空间，其正交补称为左零空间，两个空间的和是 $\mathbb{R}^{n}$
- 由 $X$ 的行向量张成的空间叫做行空间，其正交补称为右零空间，两个空间的和是 $\mathbb{R}^{D}$ 

为什么 $X$ 的列空间（记作 $C(X)$）和左零空间的和是 $R^{n}$ 呢？这是因为 $X$ 的列向量都是 $n$ 维的，必须要 $n$ 个坐标才能完美地表达这些列向量（然而，请注意：对于一般的工程中应用到的数据矩阵，列空间的实际维数远远不及 $n$！）。$X$ 的行空间同理。

接下来，我们将依赖于 SVD 来说明四个子空间。


### 列空间和左零空间
SVD 的最大作用就是找到了列空间和左零空间的一组基底。考虑
$$
X = USV^T
$$
![[Pasted image 20230311235350.png]]

我们可以将 $U$ 写成列向量的形式、，也就是 $U = [u_{1},u_{2},\cdots ,u_{r},u_{r+1},\cdots ,u_{n}]$ ，显然，从 $u_{r+1}$ 到 $u_{n}$ 的一系列列向量是在乘法运算的过程中没用的！那么它们可以被删去，从而将完全型 SVD 变成紧凑型 SVD 

众所周知，矩阵 $X$ 的秩 $r$ 也就是它的列秩，也就是说，只要 $r$ 个线性无关的向量就可以张成 $X$ 的列空间。由于 $U$ 的各个列向量都是互相垂直的，必定线性无关，那么我们可以选择 $u_{1},\cdots,u_{r}$ 来作为 $X$ 的列空间的一组基。

接下来我们说明，$u_{r+1},\cdots ,u_{n}$ 可以作为 $X$ 的左零空间的一组基。要证明这一点，只需将 $X$ 的各个列向量向着 $u_{r+1},\cdots,u_{n}$ 张成的空间上投影。
考虑到：
$$
X^{T} = VS^{T}U^{T} \ \ \Rightarrow \ \ X^{T}U = VS^{T}
$$
显然，经过运算（从图中）可以看出，$X$ 的每一个列向量向着其左零空间的每一个基向量上的投影全是 0。
![[Pasted image 20230312000951.png]]

### 行空间和右零空间
想知道行空间是什么，我们可以将 $X$ 转置，再重复一次上述过程。
![[Pasted image 20230312001540.png]]
显然我们可以发现，在 $V= [v_{1},v_{2},\cdots ,v_{D}]$ 的列向量中，$v_{r+1},\cdots ,v_{D}$ 这一部分完全没用。因此，只要选择 $v_{1},\cdots v_{r}$ 这些向量，就可以张成 $X$ 的行空间，其余的向量则是 $X$ 的右零空间的基底。

要说明这点也很简单，只要做一次与上面相同的过程：
![[Pasted image 20230312001913.png]]
将 $X$ 的行向量向着这些基底上投影，得到的结果都是 0.

### 几何上的解释
我们举个例子：找个秩 1 矩阵
$$
X = \begin{bmatrix}1 & -1  \\  -\sqrt 3 & \sqrt 3  \\  2  & - 2\end{bmatrix}
$$
现在我们找它的四个空间：对 $X$ 本体 SVD 分解
![[Pasted image 20230312003127.png|450]]

取 $U$ 的第一列作为列空间的基；取剩下两个作为左零空间的基。验证一下，我们投影：
![[Pasted image 20230312003242.png|450]]

从图上看：
![[Pasted image 20230312003322.png|400]]

## 关于 Gram 矩阵
首先，Gram 矩阵和余弦相似度矩阵都是在试图同时表达很多个向量的长度和方向信息。数据矩阵 $X$ 的 Gram 矩阵定义为：
$$
G = X^{T}X = (<x_{i},x_{j}>) = (||x_{i} || \ ||x_{j}|| \cos \theta_{i,j} )
$$
余弦相似度矩阵则仅仅表征了向量之间的夹角，定义为：
$$
C = (\cos <x_{i},x_{j}>) = (\cos \theta_{i,j} )
$$
那么，$X^T$ 的 Gram 矩阵显然就被定义为：$H = XX^{T}$。
为了找到 $G$ 和 $H$ 之间的关系，我们对它们分别进行特征值分解：
$$
G = V \Lambda V^T 
$$
取出其中一个特征向量 $v$，那么有：
$$
Gv = \lambda_{G}v \ \  \Rightarrow  \ \ X^{T}X v=\lambda_{G}v \qquad (\star)
$$
同理，对于 $H$，有：
$$
Hu = \lambda_{H}u \ \ \Rightarrow\ \ XX^{T}u = \lambda_{H}u
$$
由 $\star$ 式两侧同时乘以 $X$ 发现：
$$
XX^{T}Xv = \lambda_{G}Xv
$$
显然，取 $u=Xv$， $\lambda_{G}= \lambda_{H}$ 成立，这就解释了你算 SVD 的时候为什么两边算出了相同的特征值。

### Gram 矩阵和协方差的关系
显然，根据协方差的定义，我们有：
$$
X_{c}^{T}X_{c} = (n-1) \Sigma
$$
考虑到协方差矩阵的统计学意义，我们将其写为：
$$
\Sigma  = (\rho_{ij}\sigma_{i}\sigma_{j})
$$
我们发现这和 Dram 矩阵中模长、夹角的形式十分相似，$\sigma_{i}$ 和 $\sigma_{j}$ 可以被定义为两个向量的模长，而 $\rho_{ij}$ 则被定义为两个向量的夹角（其实，这个“向量”就是中心化的均值向量）
